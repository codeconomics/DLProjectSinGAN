{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQYBMHq9euMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jHZajuThl0s",
        "colab_type": "text"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCTH974_hnjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "    def print_(self):\n",
        "        print(f\"{'=' * 80}\\n{'Opts'.center(80)}\\n{'-' * 80}\")\n",
        "        for key in self:\n",
        "            if self[key]:\n",
        "                print('{:>30}: {:<30}'.format(key, self[key]).center(80))\n",
        "        print('=' * 80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMvjw1ule-yW",
        "colab_type": "text"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnFN5JV_fAfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(opts):\n",
        "    (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "    N = train_images.shape[0]   # number of sample\n",
        "    train_images = train_images.reshape(N, 28, 28, 1).astype('float32')\n",
        "    train_images = train_images / 255.0 # Normalize the images to [0, 1]\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(N).batch(opts.batch_size)\n",
        "    return train_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu1FzLxBg2FJ",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUtTNC-bg3xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_upconv2D(model, out_channel=1, kernel_size=(5,5), padding=\"same\", upconv=True, batch_norm=True, ReLu=True, conv=True):\n",
        "    if conv:\n",
        "        model.add(layers.Conv2DTranspose(out_channel, \n",
        "                                        kernel_size,\n",
        "                                        strides=(2, 2) if upconv else (1, 1),\n",
        "                                        padding=padding,\n",
        "                                        use_bias=False))\n",
        "    if batch_norm:\n",
        "        model.add(layers.BatchNormalization())\n",
        "    if ReLu:\n",
        "        model.add(layers.LeakyReLU())\n",
        "\n",
        "\n",
        "def get_generator(noise_size):\n",
        "    G = tf.keras.Sequential()\n",
        "    G.add(layers.Dense(7*7*256, \n",
        "                           use_bias=False, input_shape=(noise_size,)))\n",
        "    \n",
        "    G.add(layers.Reshape((7, 7, 256)))\n",
        "    add_upconv2D(G, conv=False, batch_norm=True, ReLu=True)\n",
        "    add_upconv2D(G, out_channel=128, kernel_size=(5,5), padding=\"same\", upconv=False, batch_norm=True, ReLu=True, conv=True)\n",
        "    add_upconv2D(G, out_channel=64, kernel_size=(5,5), padding=\"same\", upconv=True, batch_norm=True, ReLu=True, conv=True)\n",
        "    add_upconv2D(G, out_channel=1, kernel_size=(5,5), padding=\"same\", upconv=True, batch_norm=True, ReLu=True, conv=True)\n",
        "    \n",
        "    assert G.output_shape == (None, 28, 28, 1)\n",
        "    return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY7CoOhTg5P8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_G_noise(G, noise):\n",
        "    fake_img = G(noise, training=False)\n",
        "    plt.imshow(fake_img[0, :, :, 0]*255.0, cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHdE4g9kg53H",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aFk5fpAg8EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_conv(model, out_channel=1, kernel_size=(5, 5), stride=(2, 2), padding='same', ReLu=True, dropout=None, conv=True):\n",
        "    if conv:\n",
        "        model.add(layers.Conv2D(out_channel, kernel_size, strides=stride, padding=padding))\n",
        "    if ReLu:\n",
        "        model.add(layers.LeakyReLU())\n",
        "    if dropout:\n",
        "        model.add(layers.Dropout(dropout))\n",
        "\n",
        "def get_discriminator():\n",
        "    D = tf.keras.Sequential()\n",
        "    D.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "    add_conv(D, conv=False, ReLu=True, dropout=0.3)\n",
        "    add_conv(D, out_channel=128, kernel_size=(5, 5), stride=(2, 2), padding='same', ReLu=True, dropout=0.3)\n",
        "    add_conv(D, out_channel=256, kernel_size=(5, 5), stride=(2, 2), padding='same', ReLu=True, dropout=0.3)\n",
        "    \n",
        "    D.add(layers.Flatten())    \n",
        "    D.add(layers.Dense(1))\n",
        "    return D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MuyqTgGg8pb",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgviidOQg-Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define losses\n",
        "ce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def get_G_D(opts):\n",
        "    G = get_generator(opts.g_noise_size)\n",
        "    D = get_discriminator()\n",
        "    return G, D\n",
        "\n",
        "def d_loss(real_img, fake_img):\n",
        "    real_loss = ce(tf.ones_like(real_img), real_img)\n",
        "    fake_loss = ce(tf.zeros_like(fake_img), fake_img)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def g_loss(fake_pred):\n",
        "    return ce(tf.ones_like(fake_pred), fake_pred)\n",
        "\n",
        "def get_optimizers(opts):\n",
        "    G_optim = tf.keras.optimizers.Adam(opts.g_lr)\n",
        "    D_optim = tf.keras.optimizers.Adam(opts.d_lr)\n",
        "    return G_optim, D_optim\n",
        "\n",
        "@tf.function\n",
        "def training_loop(G, D, G_optim, D_optim, batch, opts):\n",
        "    noise_sample = tf.random.normal([opts.batch_size, opts.g_noise_size])\n",
        "\n",
        "    with tf.GradientTape() as G_tape, tf.GradientTape() as D_tape:\n",
        "        fake_img = G(noise_sample, training=True)\n",
        "\n",
        "        real_pred = D(batch, training=True)\n",
        "        fake_pred = D(fake_img, training=True)\n",
        "        G_loss = g_loss(fake_pred)\n",
        "        D_loss = d_loss(real_pred, fake_pred)\n",
        "    \n",
        "    G_grad = G_tape.gradient(G_loss, G.trainable_variables)\n",
        "    D_grad = D_tape.gradient(D_loss, D.trainable_variables)\n",
        "    G_optim.apply_gradients(zip(G_grad, G.trainable_variables))\n",
        "    D_optim.apply_gradients(zip(D_grad, D.trainable_variables))\n",
        "\n",
        "def train_model(opts):\n",
        "    G, D = get_G_D(opts)\n",
        "    G_optim, D_optim = get_optimizers(opts)\n",
        "    dataset = load_dataset(opts)\n",
        "\n",
        "    fix_noise = tf.random.normal([opts.num_fix_samples, opts.g_noise_size])\n",
        "\n",
        "    for epoch in range(opts.epochs):\n",
        "        \n",
        "        for batch in dataset:\n",
        "            try:\n",
        "                training_loop(G, D, G_optim, D_optim, batch, opts)\n",
        "            except KeyboardInterrupt:\n",
        "                print('Exiting early from training.')\n",
        "                return G, D\n",
        "        display.clear_output(wait=True)\n",
        "        plot_G_noise(G, fix_noise)\n",
        "    return G, D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wua6xzxXg-x9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkbHQh6khgFv",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrzWPVr2hfwF",
        "colab_type": "code",
        "outputId": "36cd6c3e-b454-4866-a7e7-4c6e86f1b0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "            'image_size':32,  \n",
        "            'image_channel':1,\n",
        "            'g_noise_size':100,\n",
        "            'num_fix_samples':1,\n",
        "            # 'opt_lr':0.0003,\n",
        "            'g_lr':0.001,\n",
        "            'd_lr':0.001,\n",
        "            # 'opt_beta1':0.5,\n",
        "            # 'opt_beta2':0.999,\n",
        "            'batch_size':32, \n",
        "            'sample_dir': 'samples_gan',\n",
        "            'log_step':200,\n",
        "            'sample_every':200,\n",
        "            'epochs':50}\n",
        "\n",
        "args.update(args_dict)\n",
        "args.print_()\n",
        "G, D = train_model(args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}