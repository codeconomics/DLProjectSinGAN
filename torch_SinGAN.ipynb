{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from skimage import io as img\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor version resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_resize_tensor(img,scale_factor,opt):\n",
    "    \"\"\"wrapper for resize function, img_resize_main is for w*h*c format\"\"\"\n",
    "    img = tensor_to_np_format_tensor(img)\n",
    "    img = img_resize_main(img, scale_factor, opt.device)\n",
    "    img = np_format_tensor_to_tensor(img)\n",
    "    return img\n",
    "\n",
    "def tensor_to_np_format_tensor(x):\n",
    "    \"\"\"convert a [-1,1] s*c*w*h tensor to a [0,255] w*h*c tensor\"\"\"\n",
    "    x = denorm(x[0].permute((1,2,0)))*255\n",
    "    return x\n",
    "\n",
    "def np_format_tensor_to_tensor(x):\n",
    "    \"\"\"convert a [0,255] w*h*c tensor to a [-1,1] s*c*w*h tensor\"\"\"\n",
    "    x = x[:,:,:,None].permute(3, 2, 0, 1)/255\n",
    "    return norm(x)\n",
    "\n",
    "def img_resize_main(img, scale_factor, device):\n",
    "    #for normal image, rescale the first 2 dim, with channel remain 1\n",
    "    scale_factor = torch.tensor([scale_factor, scale_factor, 1], device = device)\n",
    "    output_shape = torch.ceil(torch.cuda.FloatTensor(list(img.shape)) * scale_factor)\n",
    "    #define the interpolation method\n",
    "    method = cubic\n",
    "    #define the kernel width\n",
    "    kernel_width = torch.tensor(4.0, device = device)\n",
    "    #if we are scaling down use antialising\n",
    "    antialiasing = (scale_factor[0] < 1)\n",
    "    \n",
    "    sorted_dims = torch.argsort(scale_factor)\n",
    "    out_image = img.clone()\n",
    "    for dim in sorted_dims:\n",
    "        #for non-scaled dim, nothing happened\n",
    "        if scale_factor[dim] == 1:\n",
    "            continue\n",
    "        # for each coordinate (along dim), calculate which coordinates in the input image affect its result and the\n",
    "        # weights that multiply the values there to get its result.\n",
    "        weights, field_of_view = contributions(in_length = img.shape[dim.item()], \n",
    "                                                 out_length = output_shape[dim.item()], \n",
    "                                                 scale = scale_factor[dim.item()],\n",
    "                                                 kernel = method, \n",
    "                                                 kernel_width = kernel_width, \n",
    "                                                 antialiasing = antialiasing,\n",
    "                                                 device = device)\n",
    "        #resize the image by one dimension\n",
    "        out_image = resize_along_dim(image = out_image, \n",
    "                                       dim = dim, \n",
    "                                       weights = weights, \n",
    "                                       field_of_view = field_of_view,\n",
    "                                       device = device)\n",
    "        \n",
    "    return out_image\n",
    "\n",
    "def cubic(x):\n",
    "    \"\"\"cubic interpolation, for tensor\"\"\"\n",
    "    absx = torch.abs(x)\n",
    "    absx2 = absx ** 2\n",
    "    absx3 = absx ** 3\n",
    "    return ((1.5*absx3 - 2.5*absx2 + 1) * (absx <= 1) +\n",
    "            (-0.5*absx3 + 2.5*absx2 - 4*absx + 2) * ((1 < absx) & (absx <= 2)))\n",
    "\n",
    "def contributions(in_length, out_length, scale, kernel, kernel_width, antialiasing, device):\n",
    "    \"\"\"get the weight and view\"\"\"\n",
    "    # When anti-aliasing is activated, the receptive field is stretched to size of\n",
    "    # 1/sf. this means filtering is more 'low-pass filter'.\n",
    "    fixed_kernel = (lambda arg: scale * kernel(scale * arg)) if antialiasing else kernel\n",
    "    kernel_width *= 1.0 / scale if antialiasing else 1.0\n",
    "    \n",
    "    # coordinates of the output image\n",
    "    out_coordinates = torch.arange(1, out_length.item()+1, device = device)\n",
    "    \n",
    "    match_coordinates = 1.0 * out_coordinates / scale + 0.5 * (1 - 1.0 / scale)\n",
    "    # This is the left boundary to start multiplying the filter from, it depends on the size of the filter\n",
    "    left_boundary = torch.floor(match_coordinates - kernel_width / 2)\n",
    "    \n",
    "    # Kernel width needs to be enlarged because when covering has sub-pixel borders, it must 'see' the pixel centers\n",
    "    # of the pixels it only covered a part from. So we add one pixel at each side to consider (weights can zeroize them)\n",
    "    expanded_kernel_width = torch.ceil(kernel_width) + 2\n",
    "    \n",
    "    #Determine a set of field_of_view for each each output position, \n",
    "    #these are the pixels in the input image that the pixel in the output image 'sees'.\n",
    "    field_of_view = torch.squeeze((torch.unsqueeze(left_boundary, 1) + \\\n",
    "                                   torch.arange(expanded_kernel_width.item(),device = device) - 1).byte())\n",
    "    \n",
    "    # weight to each pixel in the field of view.\n",
    "    weights = fixed_kernel(1.0 * torch.unsqueeze(match_coordinates, 1) - field_of_view - 1)\n",
    "    \n",
    "    # standardize the weights\n",
    "    sum_weights = torch.sum(weights, 1)\n",
    "    sum_weights[sum_weights == 0] = 1.0\n",
    "    weights = 1.0 * weights / torch.unsqueeze(sum_weights, 1)\n",
    "    \n",
    "    #(0,1,2,...in_length-1,in_length-1,in_length-2,...1,0),reflection padding at the boundaries\n",
    "    mirror = torch.cat((torch.arange(in_length, device = device), \n",
    "                        torch.arange(in_length - 1, -1, step=-1,device = device)))\n",
    "    index = torch.fmod(field_of_view, mirror.shape[0]).type(torch.cuda.LongTensor)\n",
    "    \n",
    "    # Get rid of  weights and pixel positions that are of zero weight\n",
    "    field_of_view = torch.take(mirror,index)\n",
    "    non_zero_out_pixels = torch.squeeze(torch.nonzero(weights.type(torch.bool).any(dim=0)))\n",
    "    weights = torch.squeeze(weights[:, non_zero_out_pixels])\n",
    "    field_of_view = torch.squeeze(field_of_view[:, non_zero_out_pixels])\n",
    "    \n",
    "    # Final products are the relative positions and the matching weights, both are output_size X fixed_kernel_size\n",
    "    return weights, field_of_view\n",
    "\n",
    "def resize_along_dim(image, dim, weights, field_of_view, device):\n",
    "    \"\"\"scale along one dimension\"\"\"\n",
    "    #use dim 0 as the dim be scaled\n",
    "    tmp_im = torch.transpose(image, dim, 0)\n",
    "    \n",
    "    weights = torch.reshape(weights.T, list(weights.T.shape) + (image.dim() - 1) * [1])\n",
    "    temp = tmp_im[field_of_view.T]\n",
    "    tmp_out_im = torch.sum(temp * weights.expand(temp.shape).cuda(), dim=0)\n",
    "    # swap back the axes to the original order\n",
    "    return torch.transpose(tmp_out_im, dim, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opt setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    \"\"\"create a namespace\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    #workspace:\n",
    "    parser.add_argument('--input_name')\n",
    "    parser.add_argument('--input_dir', default = os.path.join(os.getcwd(), \"input\"))\n",
    "    parser.add_argument('--out', default=os.path.join(os.getcwd(), \"output\"))\n",
    "    parser.add_argument('--manualSeed', type = int, default=1)\n",
    "\n",
    "    #networks hyper parameters:\n",
    "    parser.add_argument('--nfc', type=int, default=32)\n",
    "    parser.add_argument('--min_nfc', type=int, default=32)\n",
    "    parser.add_argument('--ker_size',type=int,help='kernel size',default=3)\n",
    "    parser.add_argument('--num_layer',type=int,help='number of layers',default=5)\n",
    "    parser.add_argument('--stride',help='stride',default=1)\n",
    "    parser.add_argument('--padd_size',type=int,help='net pad size',default=0)#math.floor(opt.ker_size/2)\n",
    "        \n",
    "    #pyramid parameters:\n",
    "    parser.add_argument('--scale_factor',type=float,help='pyramid scale factor',default=0.75)#pow(0.5,1/6))\n",
    "    parser.add_argument('--noise_amp',type=float,help='addative noise cont weight',default=0.1)\n",
    "    parser.add_argument('--min_size',type=int,help='image minimal size at the coarser scale',default=25)\n",
    "    parser.add_argument('--max_size', type=int,help='image maximal size at the coarser scale', default=250)\n",
    "    parser.add_argument('--gen_start_scale', type=int, default = 0)\n",
    "    parser.add_argument('--additional_scale', type=int, default = 0)\n",
    "\n",
    "    #optimization hyper parameters:\n",
    "    parser.add_argument('--niter', type=int, default=2000, help='number of epochs to train per scale')\n",
    "    parser.add_argument('--gamma',type=float,help='scheduler gamma',default=0.1)\n",
    "    parser.add_argument('--lr_g', type=float, default=0.0005, help='learning rate, default=0.0005')\n",
    "    parser.add_argument('--lr_d', type=float, default=0.0005, help='learning rate, default=0.0005')\n",
    "    parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "    parser.add_argument('--lambda_grad',type=float, help='gradient penelty weight',default=0.1)\n",
    "    parser.add_argument('--alpha',type=float, help='reconstruction loss weight',default=10)\n",
    "\n",
    "    return parser\n",
    "\n",
    "def post_config(opt):\n",
    "    # init fixed parameters\n",
    "    opt.device = torch.device(\"cuda\")\n",
    "    opt.niter_init = opt.niter\n",
    "    opt.noise_amp_init = opt.noise_amp\n",
    "    opt.nfc_init = opt.nfc\n",
    "    opt.min_nfc_init = opt.min_nfc\n",
    "    opt.scale_factor_init = opt.scale_factor\n",
    "    random.seed(opt.manualSeed)\n",
    "    torch.manual_seed(opt.manualSeed)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    \"\"\"convert [0,1] to [-1,1] scale\"\"\"\n",
    "    out = (x -0.5) *2\n",
    "    return out.clamp(-1, 1)\n",
    "\n",
    "def denorm(x):\n",
    "    \"\"\"convert [-1,1] to [0,1] scale\"\"\"\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_tensor(x):\n",
    "    \"\"\"convert [0,255] h*w*c np.array to [-1,1] s*c*h*w tensor\"\"\"\n",
    "    x = x[:,:,:,None].transpose((3, 2, 0, 1))/255\n",
    "    x = torch.from_numpy(x).to(torch.device('cuda'))\n",
    "    x = x.type(torch.cuda.FloatTensor)\n",
    "    x = norm(x)\n",
    "    return x\n",
    "\n",
    "def tensor_to_np(x):\n",
    "    \"\"\"convert [-1,1] s*c*h*w tensor to [0,255] np.array form, never used, just in case needed\"\"\"\n",
    "    x = x[0]\n",
    "    x = x.permute((1,2,0))\n",
    "    x = 255*denorm(x)\n",
    "    x = x.cpu().numpy()\n",
    "    x = x.astype(np.uint8)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(opt):\n",
    "    \"\"\"read a image by name\"\"\"\n",
    "    x = img.imread(f'{opt.input_dir}/{opt.input_name}')\n",
    "    return np_to_tensor(x)\n",
    "\n",
    "def read_image_np_array(x):\n",
    "    \"\"\"wrapper of np_to_tensor, read from a [0,255] h*w*c array directly, never used, just in case needed\"\"\"\n",
    "    return np_to_tensor(x)\n",
    "\n",
    "def convert_image_np(img):\n",
    "    \"\"\"convert the [-1,1] tensor to [0,1] np.array form\"\"\"\n",
    "    img = denorm(img)\n",
    "    img = img[-1,:,:,:].to(torch.device('cpu'))\n",
    "    img = img.numpy().transpose((1,2,0))\n",
    "    img = np.clip(img,0,1) # bound the value in 0-1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling(img,size_x,size_y):\n",
    "    \"\"\"the wrapper for bilinear upsampling\"\"\"\n",
    "    upsample = nn.Upsample(size=[round(size_x),round(size_y)],\n",
    "                           mode='bilinear',\n",
    "                           align_corners=True)\n",
    "    return upsample(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_penalty(netD, real_data, fake_data, opt):\n",
    "    \"\"\"\n",
    "    The gradient penalty for WGAN, from article https://arxiv.org/abs/1704.00028, named WGAN-GP sometimes\n",
    "    \"\"\"\n",
    "    #generate a random interpolation between real and fake\n",
    "    mix_constant = torch.rand(1, 1, device = opt.device)\n",
    "    mix_constant = mix_constant.expand(real_data.size())\n",
    "    interpolates = mix_constant * real_data + (1 - mix_constant) * fake_data\n",
    "\n",
    "    #test the calculate the gradient of interpolation generated in discriminator\n",
    "    interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n",
    "    disc_interpolates = netD(interpolates)\n",
    "    gradients = torch.autograd.grad(outputs=disc_interpolates,\n",
    "                                    inputs=interpolates,\n",
    "                                    #The “vector” in the Jacobian-vector product. Usually gradients w.r.t. each output.\n",
    "                                    grad_outputs=torch.ones(disc_interpolates.size()).to(opt.device),\n",
    "                                    create_graph=True,\n",
    "                                    retain_graph=True,\n",
    "                                    only_inputs=True)[0]\n",
    "    \n",
    "    # by the definition of Gradient penalty\n",
    "    gradient_penalty = opt.lambda_grad * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scale_coef(real_,opt):\n",
    "    \"\"\"set all the scale related coefficient\"\"\"\n",
    "    #the number of scales is the log(min size/actual size),base scale_factor specified + 1, added two param to control\n",
    "    opt.num_scales = math.ceil((math.log(math.pow(opt.min_size / (min(real_.shape[2], real_.shape[3])), 1), opt.scale_factor_init))) + 1 + opt.additional_scale # newly added here\n",
    "    \n",
    "    #similarly, scale_to_stop is defined by the max size of lowest scale, without +1 this time\n",
    "    scale_to_stop = math.ceil(math.log(min([opt.max_size, max([real_.shape[2], real_.shape[3]])]) / max([real_.shape[2], real_.shape[3]]),opt.scale_factor_init))\n",
    "    opt.stop_scale = opt.num_scales - scale_to_stop\n",
    "    \n",
    "    #defined the first scale be 1 if upcasting, \n",
    "    opt.scale1 = min(opt.max_size / max([real_.shape[2], real_.shape[3]]),1)\n",
    "\n",
    "    real = img_resize_tensor(real_, opt.scale1, opt)\n",
    "\n",
    "    #scale factor is defined last in case there's any rounding or other issue\n",
    "    #the ratio of size to the root of opt.stop_scale\n",
    "    opt.scale_factor = math.pow(opt.min_size/(min(real.shape[2],real.shape[3])),1/(opt.stop_scale))\n",
    "    \n",
    "def generate_noise(size,device):\n",
    "    \"\"\"generate a normal noise of s*c*h*w size\"\"\"\n",
    "    return torch.randn(1, size[0], size[1], size[2], device=device)\n",
    "\n",
    "def generate_reals(real,opt):\n",
    "    \"\"\"generate the list of difference scales of real picture\"\"\"\n",
    "    #resize the real image to correct scale\n",
    "    return [img_resize_tensor(real,math.pow(opt.scale_factor,i),opt) for i in range(opt.stop_scale, -1, -1)]\n",
    "    \n",
    "def generate_directory(opt):\n",
    "    \"\"\"the directory specified in opt\"\"\"\n",
    "    return f'{opt.out}/{opt.input_name}/layer={opt.num_layer}, additional_scale={opt.additional_scale}, iteration={opt.niter}, scale_factor={opt.scale_factor_init}, alpha={opt.alpha}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coarsest(reals,opt):\n",
    "    \"\"\"pick the coarest scale real image\"\"\"\n",
    "    real = reals[opt.gen_start_scale]\n",
    "    #for fresh start\n",
    "    if opt.gen_start_scale == 0:\n",
    "        #generate from 0\n",
    "        return torch.full(real.shape, 0., device=opt.device)\n",
    "    else:\n",
    "        #otherwise start from real\n",
    "        return real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inititialize_weight(layer):\n",
    "    \"\"\"for a layer of model, initialize it's weight\"\"\"\n",
    "    if isinstance(layer,nn.Conv2d):\n",
    "        layer.weight.data.normal_(0.0, 0.02)\n",
    "    elif isinstance(layer,nn.BatchNorm2d):\n",
    "        layer.weight.data.normal_(1.0, 0.02)\n",
    "        layer.bias.data.fill_(0)\n",
    "        \n",
    "def freeze(model):\n",
    "    \"\"\"change a model from training mode to evaluating mode\"\"\"\n",
    "    #only used for disable the param's updating, for tf ver just give model untrainable is fine\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def init_NN(opt):\n",
    "    \"\"\"initialize a pair of generator and discriminator\"\"\"\n",
    "    #generator initialization:\n",
    "    G = Generator(opt).cuda()\n",
    "    G.apply(inititialize_weight)\n",
    "\n",
    "    #discriminator initialization:\n",
    "    D = Discriminator(opt).cuda()\n",
    "    D.apply(inititialize_weight)\n",
    "    return G, D\n",
    "    \n",
    "\n",
    "def save_in_scale(netG,netD,z,directory):\n",
    "    \"\"\"save the model and the cumulated noise, called in the sclae\"\"\"\n",
    "    torch.save(netG.state_dict(), f'{directory}/netG.pth')\n",
    "    torch.save(netD.state_dict(), f'{directory}/netD.pth')\n",
    "    torch.save(z, f'{directory}/z_opt.pth')\n",
    "    \n",
    "def save_checkpoint(Zs,Gs,NoiseAmp, directory):\n",
    "    \"\"\"save the checkpoints of training\"\"\"\n",
    "    torch.save(Zs, f'{directory}/Zs.pth')\n",
    "    torch.save(Gs, f'{directory}/Gs.pth')\n",
    "    torch.save(NoiseAmp, f'{directory}/NoiseAmp.pth')\n",
    "    \n",
    "def load_trained_model(directory):\n",
    "    \"\"\"get the direction and load every model trained\"\"\"    \n",
    "    if(os.path.exists(directory)):\n",
    "        Gs = torch.load(f'{directory}/Gs.pth')\n",
    "        Zs = torch.load(f'{directory}/Zs.pth')\n",
    "        reals = torch.load(f'{directory}/reals.pth')\n",
    "        NoiseAmp = torch.load(f'{directory}/NoiseAmp.pth')\n",
    "        return Gs,Zs,reals,NoiseAmp\n",
    "    else:\n",
    "        raise RuntimeError('no specified trained model exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model is from the original version\n",
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(self, in_channel, out_channel, ker_size, padd, stride):\n",
    "        super(ConvBlock,self).__init__()\n",
    "        self.add_module('conv',nn.Conv2d(in_channel,\n",
    "                                         out_channel,\n",
    "                                         kernel_size=ker_size,\n",
    "                                         stride=stride,\n",
    "                                         padding=padd)),\n",
    "        self.add_module('norm',nn.BatchNorm2d(out_channel)),\n",
    "        self.add_module('LeakyRelu',nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Generator, self).__init__()\n",
    "        self.is_cuda = torch.cuda.is_available()\n",
    "        N = opt.nfc\n",
    "        self.head = ConvBlock(3,N,opt.ker_size,opt.padd_size,1)\n",
    "        self.body = nn.Sequential()\n",
    "        for i in range(opt.num_layer-2):\n",
    "            N = int(opt.nfc/pow(2,(i+1)))\n",
    "            block = ConvBlock(max(2*N,opt.min_nfc),\n",
    "                              max(N,opt.min_nfc),\n",
    "                              opt.ker_size,\n",
    "                              opt.padd_size,\n",
    "                              1)\n",
    "            self.body.add_module(f'block{i+1}',block)\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.Conv2d(max(N,opt.min_nfc),3,kernel_size=opt.ker_size,stride =1,padding=opt.padd_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        x = self.head(x)\n",
    "        x = self.body(x)\n",
    "        x = self.tail(x)\n",
    "        #have y in the center of x with correct shape of x\n",
    "        h_width = int((y.shape[2]-x.shape[2])/2)\n",
    "        w_width = int((y.shape[3]-x.shape[3])/2)\n",
    "        y = y[:,:,h_width:(y.shape[2]-h_width),w_width:(y.shape[3]-w_width)]\n",
    "        return x+y\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.is_cuda = torch.cuda.is_available()\n",
    "        N = int(opt.nfc)\n",
    "        self.head = ConvBlock(3,N,opt.ker_size,opt.padd_size,1)\n",
    "        self.body = nn.Sequential()\n",
    "        for i in range(opt.num_layer-2):\n",
    "            N = int(opt.nfc/pow(2,(i+1)))\n",
    "            block = ConvBlock(max(2*N,opt.min_nfc),\n",
    "                              max(N,opt.min_nfc),\n",
    "                              opt.ker_size,\n",
    "                              opt.padd_size,\n",
    "                              1)\n",
    "            self.body.add_module(f'block{i+1}',block)\n",
    "        self.tail = nn.Conv2d(max(N,opt.min_nfc),\n",
    "                              1,\n",
    "                              kernel_size=opt.ker_size,\n",
    "                              stride=1,\n",
    "                              padding=opt.padd_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.head(x)\n",
    "        x = self.body(x)\n",
    "        x = self.tail(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(Gs,Zs,reals,NoiseAmp,in_s,mode,padding,opt):\n",
    "    \"\"\"generate a image scale by scale from the bottom\n",
    "       when in \"random_noise\" mode, everytime use a newly generated noise z\n",
    "       when in \"Z_opt\" mode, use Z_opt recorded\n",
    "    \"\"\"\n",
    "    # if it's the first scale, do nothing, return G_z = in_s\n",
    "    G_z = in_s\n",
    "    if len(Gs) > 0:\n",
    "        # if in random mode\n",
    "        if mode == 'random_noise':\n",
    "            count = 0\n",
    "            pad_noise = int(((opt.ker_size-1)*opt.num_layer)/2)\n",
    "            #from each scale\n",
    "            for G,Z_opt,real_curr,real_next,noise_amp in zip(Gs,Zs,reals,reals[1:],NoiseAmp):\n",
    "                # for the first loop\n",
    "                if count == 0:\n",
    "                    #generate the 1 channel noise, broadcast it to correct shape\n",
    "                    z = generate_noise([1, Z_opt.shape[2] - 2 * pad_noise, Z_opt.shape[3] - 2 * pad_noise], device=opt.device)\n",
    "                    z = z.expand(1, 3, z.shape[2], z.shape[3])\n",
    "                else:\n",
    "                    #direct generate the noise in 3 channel\n",
    "                    z = generate_noise([3,Z_opt.shape[2] - 2 * pad_noise, Z_opt.shape[3] - 2 * pad_noise], device=opt.device)\n",
    "                #have a noise surrouded by 0, in shape of Z_opt\n",
    "                z = padding(z)\n",
    "    #------------------------------------------------------------\n",
    "                G_z = padding(G_z)\n",
    "                #amplify the generated noise, then add with the G_z\n",
    "                z_in = noise_amp*z+G_z\n",
    "                #generate a new output use noise-lized G_z with G_z\n",
    "                G_z = G(z_in.detach(),G_z)\n",
    "                #resize the graph up with 1/opt.scale_factor\n",
    "                G_z = img_resize_tensor(G_z,1/opt.scale_factor,opt)\n",
    "                #in case there's rounding issue\n",
    "                G_z = G_z[:,:,0:real_next.shape[2],0:real_next.shape[3]]\n",
    "                count += 1\n",
    "        if mode == 'Z_opt':\n",
    "            #the only difference is using Z_opt rather than random z\n",
    "            for G,Z_opt,real_curr,real_next,noise_amp in zip(Gs,Zs,reals,reals[1:],NoiseAmp):\n",
    "                G_z = padding(G_z)\n",
    "                z_in = noise_amp*Z_opt+G_z # for here we use Z_opt instead of generated noise\n",
    "                G_z = G(z_in.detach(),G_z)\n",
    "                G_z = img_resize_tensor(G_z,1/opt.scale_factor,opt)\n",
    "                G_z = G_z[:,:,0:real_next.shape[2],0:real_next.shape[3]]\n",
    "    return G_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_scale(reals, Gs, Zs, in_s, NoiseAmp, opt, scale_num):\n",
    "    \"\"\"train every single scale of WGAN, with additional gradient penalty and LSGAN loss\"\"\"\n",
    "    # get the current resized real picture\n",
    "    real = reals[len(Gs)] \n",
    "    opt.real_x, opt.real_y = real.shape[2],real.shape[3]\n",
    "\n",
    "    #padding width\n",
    "    pad = int(((opt.ker_size - 1) * opt.num_layer) / 2)\n",
    "    padding = nn.ZeroPad2d(pad)\n",
    "\n",
    "    #get alpha from opt\n",
    "    alpha = opt.alpha\n",
    "    \n",
    "    #in the start of each scale z_opt is a tensor of size fixed_noise.shape filled with 0.\n",
    "    #actually it's always 0 after the first scale.\n",
    "    z_opt = torch.full([1,3,opt.real_x + 2*pad,opt.real_y + 2*pad],0, device=opt.device)\n",
    "    \n",
    "#-------------------------model and optimizer setting-------------------\n",
    "\n",
    "    #model and optimizer setting\n",
    "    netG,netD = init_NN(opt)\n",
    "\n",
    "    #if the number of channel of previous layer = current nfc\n",
    "    #i.e. the scale is not in the same bin of 4\n",
    "    if (opt.nfc_prev==opt.nfc):\n",
    "        #get a warm start from last model\n",
    "        netG.load_state_dict(torch.load(f'{opt.out_}/{scale_num-1}/netG.pth'))\n",
    "        netD.load_state_dict(torch.load(f'{opt.out_}/{scale_num-1}/netD.pth'))\n",
    "\n",
    "    # setup optimizer and learning rate, following the original setting\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=opt.lr_d, betas=(opt.beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=opt.lr_g, betas=(opt.beta1, 0.999))\n",
    "    schedulerD = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerD,milestones=[1600],gamma=opt.gamma)\n",
    "    schedulerG = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerG,milestones=[1600],gamma=opt.gamma)\n",
    "    \n",
    "#-------------------------training-------------------\n",
    "\n",
    "    \n",
    "    #for number of loop specified\n",
    "    for epoch in tqdm(range(opt.niter), desc = f\"scale {len(Gs)}\", leave = False):\n",
    "        #if it's the first scale, for G need an additional imput\n",
    "        if (Gs == []):\n",
    "            #generate a 1 channel noise of size [1,opt.real_x,opt.real_y],give it correct shape and zero pad\n",
    "            z_opt = generate_noise([1,opt.real_x,opt.real_y], device=opt.device)\n",
    "            z_opt = padding(z_opt.expand(1,3,opt.real_x,opt.real_y))\n",
    "            #generate another 1 channel noise of size [1,opt.real_x,opt.real_y],give it correct shape and zero pad\n",
    "            noise_ = generate_noise([1,opt.real_x,opt.real_y], device=opt.device)\n",
    "            noise_ = padding(noise_.expand(1,3,opt.real_x,opt.real_y))\n",
    "        # when it's not the first scale\n",
    "        else:\n",
    "            #generate 3-channel noise is fine\n",
    "            noise_ = generate_noise([3,opt.real_x,opt.real_y], device=opt.device)\n",
    "            noise_ = padding(noise_)\n",
    "\n",
    "        #-------------dicriminator-----------------\n",
    "\n",
    "        for j in range(3):\n",
    "            \n",
    "            netD.zero_grad()\n",
    "            # train with real, generate a result, to minimize -D(True) + D(G(noise)), the mean should be negative\n",
    "            output = netD(real).to(opt.device)\n",
    "            errD_real = -output.mean()#mean of a matrix\n",
    "            errD_real.backward(retain_graph=True)\n",
    "\n",
    "            # generate the noise\n",
    "            # for the first loop in the first epoch\n",
    "            if (j==0) & (epoch == 0):\n",
    "                #if it's the first scale(very first loop)\n",
    "                if (Gs == []):\n",
    "                    #set prev to all 0, zero padding\n",
    "                    prev = torch.full([1,3,opt.real_x,opt.real_y], 0., device=opt.device)\n",
    "                    in_s = prev\n",
    "                    prev = padding(prev)\n",
    "\n",
    "                    #set z_prev to all 0,padding\n",
    "                    z_prev = torch.full([1,3,opt.real_x,opt.real_y], 0., device=opt.device)\n",
    "                    z_prev = padding(z_prev)\n",
    "\n",
    "                    opt.noise_amp = 1\n",
    "                #if it's the first loop of other scales\n",
    "                else:\n",
    "                    # generate a result from bottom to current-1 scale, all from random noise\n",
    "                    prev = forward_pass(Gs,Zs,reals,NoiseAmp,in_s,'random_noise',padding,opt)\n",
    "                    prev = padding(prev)\n",
    "                    \n",
    "                    # generate a result from bottom to current-1 scale, all by Z_opt\n",
    "                    z_prev = forward_pass(Gs,Zs,reals,NoiseAmp,in_s,'Z_opt',padding,opt)\n",
    "                    \n",
    "                    #update the noise amplifier by the RMSE between actual and best result z_prev\n",
    "                    criterion = nn.MSELoss()\n",
    "                    RMSE = torch.sqrt(criterion(real, z_prev))\n",
    "                    opt.noise_amp = opt.noise_amp_init*RMSE\n",
    "                    \n",
    "                    # add a padding after the correct shape is used for RMSE\n",
    "                    z_prev = padding(z_prev)\n",
    "\n",
    "            #for non-first loop\n",
    "            else:\n",
    "                # generate a result from bottom to current-1 scale, all from random noise\n",
    "                prev = forward_pass(Gs,Zs,reals,NoiseAmp,in_s,'random_noise',padding,opt)\n",
    "                prev = padding(prev)\n",
    "\n",
    "            #if it's the first scale\n",
    "            if (Gs == []):\n",
    "                #use the noise_ as \"formal\" one\n",
    "                noise = noise_\n",
    "            else:\n",
    "                #amplify the padded noise then add prev\n",
    "                noise = opt.noise_amp*noise_+prev\n",
    "\n",
    "            # train with fake generated from noise, to minimize -D(true) + D(G(noise)), \n",
    "            # the output should be positive to be minimized\n",
    "            fake = netG(noise.detach(),prev)\n",
    "            output = netD(fake.detach())\n",
    "            errD_fake = output.mean()\n",
    "            errD_fake.backward(retain_graph=True)\n",
    "\n",
    "            #calculate the penalty,calculate gradient penalty on to D(the ref see doc of this function)\n",
    "            gradient_penalty = get_gradient_penalty(netD, real, fake, opt)\n",
    "            gradient_penalty.backward()\n",
    "\n",
    "            optimizerD.step()\n",
    "            \n",
    "        schedulerD.step()\n",
    "\n",
    "        #-----------generator------------------\n",
    "\n",
    "        for j in range(3):\n",
    "            # init to 0, generate the output from the discrimator, minimize -D(G(z))\n",
    "            netG.zero_grad()\n",
    "            output = netD(fake)\n",
    "            errG = -output.mean()\n",
    "            errG.backward(retain_graph=True)\n",
    "\n",
    "            #use some idea of LSGAN(https://arxiv.org/pdf/1611.04076.pdf), have alpha*MSE as a part of loss\n",
    "            #amplify the z and add them into a \"cumulative weighted sum\" of Z\n",
    "            Z_opt = opt.noise_amp*z_opt+z_prev\n",
    "            loss = nn.MSELoss()\n",
    "            rec_loss = alpha*loss(netG(Z_opt.detach(),z_prev),real)\n",
    "            rec_loss.backward(retain_graph=True)\n",
    "\n",
    "            optimizerG.step()\n",
    "            \n",
    "        schedulerG.step()\n",
    "\n",
    "        #at the end of the iteration save the result\n",
    "        if epoch == (opt.niter-1): \n",
    "            plt.imsave(f'{opt.outf}/fake_sample.png', convert_image_np(fake.detach()), vmin=0, vmax=1)\n",
    "            plt.imsave(f'{opt.outf}/G(z_opt).png',  convert_image_np(netG(Z_opt.detach(), z_prev).detach()), vmin=0, vmax=1)\n",
    "            torch.save(z_opt, f'{opt.outf}/z_opt.pth')\n",
    "\n",
    "    # save the models and z_opt\n",
    "    save_in_scale(netG,netD,z_opt,opt.outf)\n",
    "    \n",
    "    return freeze(netG), z_opt.detach(),in_s.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt,Gs,Zs,NoiseAmp):\n",
    "    \"\"\"the main training procedure\"\"\"\n",
    "    #from the name get the picture\n",
    "    real_ = read_image(opt)\n",
    "    opt.out_ = generate_directory(opt)\n",
    "    #scale1 is defined from adjust2scale, saved in opt\n",
    "    real = img_resize_tensor(real_,opt.scale1,opt)\n",
    "    #generate a list of resized images and save\n",
    "    reals = generate_reals(real,opt)\n",
    "    #print([i.shape for i in reals])\n",
    "    torch.save(reals, f'{opt.out_}/reals.pth')\n",
    "    opt.nfc_prev = 0\n",
    "    in_s = 0\n",
    "\n",
    "    #for scale 0 to stop scale\n",
    "    for scale_num in tqdm(range(opt.stop_scale+1), desc = opt.input_name, leave = True):\n",
    "\n",
    "        #define the number of channels and the minimum number of channels in this scale\n",
    "        opt.nfc = min(opt.nfc_init * pow(2, math.floor(scale_num / 4)), 128)\n",
    "        opt.min_nfc = min(opt.min_nfc_init * pow(2, math.floor(scale_num / 4)), 128)\n",
    "\n",
    "        #the output main directory and the output sub directory for each scale, need create the directory for the scale\n",
    "        opt.outf = f'{opt.out_}/{scale_num}'\n",
    "        try:\n",
    "            os.makedirs(opt.outf)\n",
    "        except OSError:\n",
    "                pass\n",
    "        #save the resized original image for this scale\n",
    "        plt.imsave(f'{opt.outf}/real_scale.png', convert_image_np(reals[scale_num]), vmin=0, vmax=1)\n",
    "\n",
    "        #train a single scale, get the current z, in_s, generator\n",
    "        G_curr, z_curr,in_s = train_single_scale(reals = reals,\n",
    "                                                 Gs = Gs,\n",
    "                                                 Zs = Zs,\n",
    "                                                 in_s = in_s,\n",
    "                                                 NoiseAmp = NoiseAmp,\n",
    "                                                 opt = opt,\n",
    "                                                 scale_num = scale_num\n",
    "                                                )\n",
    "        \n",
    "        # save them into the list and save the record as a \"checkpoint\"\n",
    "        Gs.append(G_curr)\n",
    "        Zs.append(z_curr)\n",
    "        NoiseAmp.append(opt.noise_amp)\n",
    "        save_checkpoint(Zs,Gs,NoiseAmp,opt.out_)\n",
    "\n",
    "        opt.nfc_prev = opt.nfc\n",
    "        \n",
    "        del G_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmentation(Gs, Zs, reals, NoiseAmp, opt, in_s=None, gen_start_scale=0, num_generated=50, save_image = False):\n",
    "    \"\"\"main generating procedure, generate num_samples augmentation images from a model\"\"\"\n",
    "    images_cur = []\n",
    "    if (save_image):\n",
    "        directory = os.path.join(generate_directory(opt),\"image_generated\")\n",
    "        try:\n",
    "            os.makedirs(directory)\n",
    "        except OSError:\n",
    "            pass\n",
    "    output_list = []\n",
    "    #for each layers\n",
    "    for G,Z_opt,noise_amp,n in zip(Gs,Zs,NoiseAmp,range(len(Gs))):\n",
    "        #generate a pad class with width ((ker_size-1)*num_layer)/2\n",
    "        pad = ((opt.ker_size-1)*opt.num_layer)/2\n",
    "        padding = nn.ZeroPad2d(int(pad))\n",
    "\n",
    "        #the shape inside padding * scale\n",
    "        real_x = int(Z_opt.shape[2]-pad*2)\n",
    "        real_y = int(Z_opt.shape[3]-pad*2)\n",
    "        noise_channel = 3\n",
    "\n",
    "        #get all the previsous image\n",
    "        images_prev = images_cur\n",
    "        images_cur = []\n",
    "        \n",
    "        #for the number of samples\n",
    "        for i in range(0,num_generated,1):\n",
    "            if n == 0:\n",
    "                #generate the single channel noise, broadcast to the correct shape\n",
    "                z_curr = generate_noise([1,real_x,real_y], device=opt.device)\n",
    "                z_curr = z_curr.expand(1,3,z_curr.shape[2],z_curr.shape[3])\n",
    "                #padding it\n",
    "                z_curr = padding(z_curr)\n",
    "            else:\n",
    "                #generate noise with defined shape\n",
    "                z_curr = generate_noise([int(3),real_x,real_y], device=opt.device)\n",
    "                #padding\n",
    "                z_curr = padding(z_curr)\n",
    "            #if it's the first scale\n",
    "            if images_prev == []:\n",
    "                #use in_s as the first one\n",
    "                I_prev = padding(in_s)\n",
    "            else:\n",
    "                #get the last image\n",
    "                I_prev = images_prev[i]\n",
    "                #resize it by 1/scale_factor\n",
    "                \n",
    "                I_prev = img_resize_tensor(I_prev,1/opt.scale_factor,opt)\n",
    "                # in case there's rounding issue\n",
    "                I_prev = I_prev[:, :, 0:reals[n].shape[2], 0:reals[n].shape[3]]\n",
    "                #padding\n",
    "                I_prev = padding(I_prev)\n",
    "                I_prev = I_prev[:,:,0:z_curr.shape[2],0:z_curr.shape[3]]\n",
    "                #upsample this piece to original shape, with bilinear policy\n",
    "                I_prev = upsampling(I_prev,z_curr.shape[2],z_curr.shape[3])\n",
    "\n",
    "            # amplify the z by the param, add the previous graph\n",
    "            z_in = noise_amp*(z_curr)+I_prev\n",
    "\n",
    "            # pass this value and previous graph to generator, get the value\n",
    "            I_curr = G(z_in.detach(),I_prev)\n",
    "\n",
    "            #for the last loop\n",
    "            if n == len(reals)-1:\n",
    "                img = I_curr.detach()\n",
    "                # have the generated image into the list\n",
    "                output_list.append(convert_image_np(img))\n",
    "                if (save_image):\n",
    "                    #save the new generated image\n",
    "                    plt.imsave(f'{directory}/{i}.png', convert_image_np(img), vmin=0,vmax=1)\n",
    "            images_cur.append(I_curr)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input_name, layer_number = 5, epochs = 2000, additional_scale = 0):\n",
    "    \"\"\"wrapper of whole training procedure\"\"\"\n",
    "    #configure the option\n",
    "    parser_train = get_arguments()\n",
    "    opt_train = parser_train.parse_args([\"--input_name\", input_name, \n",
    "                                         \"--gen_start_scale\", str(0),\n",
    "                                         \"--num_layer\", str(layer_number),\n",
    "                                         \"--niter\", str(epochs),\n",
    "                                         \"--additional_scale\", str(additional_scale),\n",
    "                                        ])\n",
    "    opt_train = post_config(opt_train)\n",
    "    # follows the SinGan operation process, slightly simplified\n",
    "    Gs = []\n",
    "    Zs = []\n",
    "    NoiseAmp = []\n",
    "    #save path(note this function is modified)\n",
    "    directory = generate_directory(opt_train)\n",
    "    #if there's existed direction, stop it\n",
    "    if (os.path.exists(directory)):\n",
    "        print(f'layer={opt_train.num_layer}, scale = {opt_train.additional_scale},iteration={opt_train.niter}, scale_factor={opt_train.scale_factor_init}, alpha={opt_train.alpha} model for {opt_train.input_name} already exist')\n",
    "    #else run the training\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(directory)\n",
    "        except OSError:\n",
    "            pass\n",
    "        #read the image\n",
    "        real = read_image(opt_train)\n",
    "        #decide scales\n",
    "        generate_scale_coef(real, opt_train)\n",
    "        #train\n",
    "        train(opt_train, Gs, Zs, NoiseAmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dataset, \n",
    "                  class_label = 3, \n",
    "                  layer_number = 5, \n",
    "                  additional_scale = 0, \n",
    "                  generate_size = 50, \n",
    "                  model_size = 5, \n",
    "                  generate_start_scale = 0):\n",
    "    \"\"\"wrapper of whole augmentation data generating procedure, \n",
    "       generate ceil(generate_size/model_size) form from each model, shuffle, return generate_size of them\n",
    "       the data returned is in s*h*w*c [0,1] images np.array form\n",
    "    \"\"\"\n",
    "    #Configures\n",
    "    INPUT_NAME = [f\"{dataset}_{class_label}_input_{i}.png\" for i in range(model_size)]\n",
    "    # the list takes all the result\n",
    "    output = []\n",
    "    parser_generate = get_arguments()\n",
    "    # for all the trained samples\n",
    "    for i in tqdm(range(model_size), desc = \"loading\", leave = False):\n",
    "        #run standard procedure, create a namespace\n",
    "        opt_generate = parser_generate.parse_args([\"--input_name\", INPUT_NAME[i], \n",
    "                                                   \"--gen_start_scale\", str(generate_start_scale),\n",
    "                                                   \"--num_layer\", str(layer_number),\n",
    "                                                   \"--additional_scale\", str(additional_scale),\n",
    "                                                  ])\n",
    "        opt_generate = post_config(opt_generate)\n",
    "        \n",
    "        directory = generate_directory(opt_generate)\n",
    "        #read the file\n",
    "        real = read_image(opt_generate)\n",
    "        #adjust scales, write into opt_generate\n",
    "        generate_scale_coef(real, opt_generate)\n",
    "        Gs, Zs, reals, NoiseAmp = load_trained_model(directory)\n",
    "        #generate coarest graph\n",
    "        in_s = generate_coarsest(reals, opt_generate)\n",
    "        #generate the output(the function is modified to generate list_output)\n",
    "        list_output = generate_augmentation(Gs, Zs, reals, NoiseAmp, opt_generate, in_s,\n",
    "                                            gen_start_scale=opt_generate.gen_start_scale, \n",
    "                                            num_generated = int(np.ceil(generate_size/model_size)),\n",
    "                                            save_image = False)\n",
    "        output += list_output\n",
    "        \n",
    "    output = np.array(output)\n",
    "    np.random.shuffle(output)\n",
    "    return output[:generate_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 0\n",
    "LAYER_NUMBER = 5\n",
    "ADDITIONAL_SCALE = 0\n",
    "train_model(f\"GTSRB_33_input_{K}.png\", layer_number = LAYER_NUMBER, additional_scale = ADDITIONAL_SCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset: [\"MNIST\", \"CIFAR10\", \"GTSRB\"]:  \n",
    "MNIST: label 0-9 [2,4,7]  \n",
    "CIFAR10: label 0-9  [3,8,9]  \n",
    "GTSRB: label 0-41  [13,15,33]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
